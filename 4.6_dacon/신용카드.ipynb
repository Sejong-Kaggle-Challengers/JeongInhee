{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "신용카드",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSOICIxzEAX1"
      },
      "source": [
        "https://auto.gluon.ai/stable/tutorials/tabular_prediction/tabular-kaggle.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adb1wi5k1FAH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "gcOuX1Yc1IH9",
        "outputId": "d4cec657-3710-45d6-d7d0-a0950e3fa9a3"
      },
      "source": [
        "train=pd.read_csv(\"train.csv\")\n",
        "test=pd.read_csv(\"test.csv\")\n",
        "\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>child_num</th>\n",
              "      <th>income_total</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>FLAG_MOBIL</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>Municipal apartment</td>\n",
              "      <td>-13899</td>\n",
              "      <td>-4709</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>247500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-11380</td>\n",
              "      <td>-1540</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>450000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-19087</td>\n",
              "      <td>-4434</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-15088</td>\n",
              "      <td>-2092</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-37.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>157500.0</td>\n",
              "      <td>State servant</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-15037</td>\n",
              "      <td>-2105</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-26.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26452</th>\n",
              "      <td>26452</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "      <td>225000.0</td>\n",
              "      <td>State servant</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-12079</td>\n",
              "      <td>-1984</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Core staff</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26453</th>\n",
              "      <td>26453</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Separated</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-15291</td>\n",
              "      <td>-2475</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-47.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26454</th>\n",
              "      <td>26454</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>292500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>With parents</td>\n",
              "      <td>-10082</td>\n",
              "      <td>-2015</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Core staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-25.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26455</th>\n",
              "      <td>26455</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>171000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Incomplete higher</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-10145</td>\n",
              "      <td>-107</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-59.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26456</th>\n",
              "      <td>26456</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>81000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-19569</td>\n",
              "      <td>-1013</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Security staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-9.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26457 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index gender car  ... family_size  begin_month  credit\n",
              "0          0      F   N  ...         2.0         -6.0     1.0\n",
              "1          1      F   N  ...         3.0         -5.0     1.0\n",
              "2          2      M   Y  ...         2.0        -22.0     2.0\n",
              "3          3      F   N  ...         2.0        -37.0     0.0\n",
              "4          4      F   Y  ...         2.0        -26.0     2.0\n",
              "...      ...    ...  ..  ...         ...          ...     ...\n",
              "26452  26452      F   N  ...         4.0         -2.0     1.0\n",
              "26453  26453      F   N  ...         2.0        -47.0     2.0\n",
              "26454  26454      F   Y  ...         2.0        -25.0     2.0\n",
              "26455  26455      M   N  ...         1.0        -59.0     2.0\n",
              "26456  26456      F   N  ...         2.0         -9.0     2.0\n",
              "\n",
              "[26457 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od6UZ9D-17f1",
        "outputId": "f12572ba-e767-4f40-d9ef-5ac0e8922cf9"
      },
      "source": [
        "train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index               0\n",
              "gender              0\n",
              "car                 0\n",
              "reality             0\n",
              "child_num           0\n",
              "income_total        0\n",
              "income_type         0\n",
              "edu_type            0\n",
              "family_type         0\n",
              "house_type          0\n",
              "DAYS_BIRTH          0\n",
              "DAYS_EMPLOYED       0\n",
              "FLAG_MOBIL          0\n",
              "work_phone          0\n",
              "phone               0\n",
              "email               0\n",
              "occyp_type       8171\n",
              "family_size         0\n",
              "begin_month         0\n",
              "credit              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6KiAHby15r3"
      },
      "source": [
        "train=train.drop(labels='occyp_type',axis=1)\n",
        "test=test.drop(labels='occyp_type',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMY9Y_1-6Yfo"
      },
      "source": [
        "train=train.drop(labels='index',axis=1)\n",
        "test=test.drop(labels='index',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ErALlug53ker",
        "outputId": "e3d4b91e-75ee-43c9-fe67-5c9278756624"
      },
      "source": [
        "!pip install -U pip\n",
        "!pip install -U setuptools wheel\n",
        "!pip install -U \"mxnet<2.0.0\"\n",
        "!pip install autogluon"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/ef/60d7ba03b5c442309ef42e7d69959f73aacccd0d86008362a681c4698e83/pip-21.0.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 5.3MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.0.1\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (54.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.36.2)\n",
            "Collecting mxnet<2.0.0\n",
            "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9 MB 54 kB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.24.3)\n",
            "Installing collected packages: mxnet\n",
            "Successfully installed mxnet-1.8.0.post0\n",
            "Requirement already satisfied: autogluon in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: autogluon.vision==0.1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.1.0)\n",
            "Requirement already satisfied: autogluon.mxnet==0.1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.1.0)\n",
            "Requirement already satisfied: autogluon.core==0.1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.1.0)\n",
            "Requirement already satisfied: autogluon.extra==0.1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.1.0)\n",
            "Requirement already satisfied: autogluon.text==0.1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.1.0)\n",
            "Requirement already satisfied: autogluon.features==0.1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.1.0)\n",
            "Requirement already satisfied: autogluon.tabular[all]==0.1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.1.0)\n",
            "Requirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (1.1.5)\n",
            "Requirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (2.12.0)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (4.41.1)\n",
            "Requirement already satisfied: dill==0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (0.3.3)\n",
            "Requirement already satisfied: scikit-learn<0.25,>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy==1.5.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (1.5.4)\n",
            "Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (5.1.1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (0.8.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (3.2.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (1.17.45)\n",
            "Requirement already satisfied: paramiko>=2.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (2.7.2)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (1.19.5)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (1.3)\n",
            "Requirement already satisfied: ConfigSpace==0.4.18 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (0.4.18)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (2.23.0)\n",
            "Requirement already satisfied: distributed>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (2021.4.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.0->autogluon) (0.29.22)\n",
            "Requirement already satisfied: gluoncv<0.11.0,>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.1.0->autogluon) (0.10.1)\n",
            "Requirement already satisfied: openml in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.1.0->autogluon) (0.11.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.1.0->autogluon) (3.6.4)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.1.0->autogluon) (2.3.0)\n",
            "Requirement already satisfied: Pillow<=8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.mxnet==0.1.0->autogluon) (7.1.2)\n",
            "Requirement already satisfied: psutil<=5.7.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.0->autogluon) (5.4.8)\n",
            "Requirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.0->autogluon) (2.5)\n",
            "Requirement already satisfied: catboost<0.25,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.0->autogluon) (0.24.4)\n",
            "Requirement already satisfied: xgboost<1.4,>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: lightgbm<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.0->autogluon) (3.2.0)\n",
            "Requirement already satisfied: fastai<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.0->autogluon) (1.0.61)\n",
            "Requirement already satisfied: torch<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.0->autogluon) (1.8.1+cu101)\n",
            "Requirement already satisfied: pyarrow>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.text==0.1.0->autogluon) (3.0.0)\n",
            "Requirement already satisfied: autogluon-contrib-nlp==0.0.1b20210201 in /usr/local/lib/python3.7/dist-packages (from autogluon.text==0.1.0->autogluon) (0.0.1b20210201)\n",
            "Requirement already satisfied: sacremoses>=0.0.38 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (0.0.44)\n",
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (3.9.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (1.5.1)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (0.1.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (0.9.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (0.1.95)\n",
            "Requirement already satisfied: contextvars in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (2.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (3.12.4)\n",
            "Requirement already satisfied: d8<1.0,>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.vision==0.1.0->autogluon) (0.0.2.post0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace==0.4.18->autogluon.core==0.1.0->autogluon) (2.4.7)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core==0.1.0->autogluon) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<0.25,>=0.23.0->autogluon.tabular[all]==0.1.0->autogluon) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<0.25,>=0.23.0->autogluon.tabular[all]==0.1.0->autogluon) (4.4.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.1.0->autogluon) (1.5.12)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.1.0->autogluon) (2.0.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.1.0->autogluon) (2.0.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.1.0->autogluon) (1.7.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.1.0->autogluon) (7.1.2)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.1.0->autogluon) (1.0.2)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.1.0->autogluon) (2.3.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.1.0->autogluon) (0.11.1)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.1.0->autogluon) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.1.0->autogluon) (54.2.0)\n",
            "Collecting dask>=2.6.0\n",
            "  Downloading dask-2021.4.0-py3-none-any.whl (941 kB)\n",
            "\u001b[K     |████████████████████████████████| 941 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.1.0->autogluon) (3.13)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-0.9.0-py3-none-any.whl (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 15.0 MB/s \n",
            "\u001b[?25hCollecting partd>=0.3.10\n",
            "  Downloading partd-1.1.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (4.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (20.9)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (2.7.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (0.9.1+cu101)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.7/dist-packages (from fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (2.2.4)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (1.3.2)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (7.352.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from fsspec>=0.6.0->dask>=2.6.0->autogluon.core==0.1.0->autogluon) (3.8.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.11.0,>=0.9.4->autogluon.extra==0.1.0->autogluon) (4.1.2.30)\n",
            "Requirement already satisfied: autocfg in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.11.0,>=0.9.4->autogluon.extra==0.1.0->autogluon) (0.0.8)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.11.0,>=0.9.4->autogluon.extra==0.1.0->autogluon) (2.3.0)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.11.0,>=0.9.4->autogluon.extra==0.1.0->autogluon) (2.2)\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.11.0,>=0.9.4->autogluon.extra==0.1.0->autogluon) (0.5.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<4.0,>=3.0->autogluon.tabular[all]==0.1.0->autogluon) (0.36.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx<3.0,>=2.3->autogluon.tabular[all]==0.1.0->autogluon) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.1.0->autogluon) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.1.0->autogluon) (2.8.1)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.1.0->autogluon) (3.2.0)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.1.0->autogluon) (3.4.7)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.1.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.1.0->autogluon) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.1.0->autogluon) (2.20)\n",
            "Collecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses>=0.0.38->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (1.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai<2.0,>=1.0->autogluon.tabular[all]==0.1.0->autogluon) (7.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->fsspec>=0.6.0->dask>=2.6.0->autogluon.core==0.1.0->autogluon) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->fsspec>=0.6.0->dask>=2.6.0->autogluon.core==0.1.0->autogluon) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.1.0->autogluon) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.1.0->autogluon) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.1.0->autogluon) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.1.0->autogluon) (1.24.3)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.1.0->autogluon) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh->autogluon.extra==0.1.0->autogluon) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh->autogluon.extra==0.1.0->autogluon) (1.1.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.1.0->autogluon) (0.3.6)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.45 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.1.0->autogluon) (1.20.45)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.1.0->autogluon) (0.10.0)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 20.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.7/dist-packages (from contextvars->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (0.15)\n",
            "Requirement already satisfied: pyflakes<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (2.3.1)\n",
            "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (0.6.1)\n",
            "Requirement already satisfied: pycodestyle<2.8.0,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.1.0->autogluon) (2.7.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.1.0->autogluon) (4.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.1.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.1.0->autogluon) (0.10.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.1.0->autogluon) (0.12.0)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.1.0->autogluon) (2.5.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<0.25,>=0.23.0->autogluon.tabular[all]==0.1.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.1.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.1.0->autogluon) (1.10.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.1.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.1.0->autogluon) (20.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.1.0->autogluon) (8.7.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.1.0->autogluon) (1.3)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: urllib3, locket, partd, fsspec, dask, portalocker\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: portalocker\n",
            "    Found existing installation: portalocker 2.3.0\n",
            "    Uninstalling portalocker-2.3.0:\n",
            "      Successfully uninstalled portalocker-2.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed dask-2021.4.0 fsspec-0.9.0 locket-0.2.1 partd-1.1.0 portalocker-2.0.0 urllib3-1.25.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dask",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1H0H0dS4_eY"
      },
      "source": [
        "from autogluon.tabular import TabularPredictor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWJQ9ls25Gf9"
      },
      "source": [
        "label = 'credit'\n",
        "eval_metric = 'log_loss'  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8YhSNV76q6T",
        "outputId": "9a9d3a1d-54b7-49f9-8e1d-a9615b4ff230"
      },
      "source": [
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, verbosity=3).fit(\n",
        "    train, presets='best_quality', time_limit=3600\n",
        "    \n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20210406_125856/\"\n",
            "Presets specified: ['best_quality']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'auto_stack': True}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': True,\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'keep_only_best': False,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'refit_full': False,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'unlabeled_data': None,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Beginning AutoGluon training ... Time limit = 3600s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20210406_125856/\"\n",
            "AutoGluon Version:  0.1.0\n",
            "Train Data Rows:    26457\n",
            "Train Data Columns: 17\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
            "\t3 unique label values:  [1.0, 2.0, 0.0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12654.3 MB\n",
            "\tTrain Data (Original)  Memory Usage: 14.39 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t\t\t('int64', 'int')     : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t\t\t('object', 'object') : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t\t\t('object', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t\t\t('object', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t16 features in original data used to generate 16 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t\t\t('object', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t\t\t('object', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t\t0.1s = Fit runtime\n",
            "\t\t\t16 features in original data used to generate 16 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t\t\t('int', [])   : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t\t\t('int', [])   : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t9 features in original data used to generate 9 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t\t\t0.0s = Fit runtime\n",
            "\t\t\t\t7 features in original data used to generate 7 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t\t0.1s = Fit runtime\n",
            "\t\t\t7 features in original data used to generate 7 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t\t0.0s = Fit runtime\n",
            "\t\t\t16 features in original data used to generate 16 features in processed data.\n",
            "\tUseless Original Features (Count: 1): ['FLAG_MOBIL']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int64', 'int')     : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', 'object') : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float64', 'float')     : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int64', 'int')         : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t0.5s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 2.09 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.63s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "Saving AutogluonModels/ag-20210406_125856/learner.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/utils/data/X.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/utils/data/y.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tNeuralNetMXNet_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.tabular_nn_model.TabularNeuralNetModel'>, 'priority': 120}}\n",
            "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 115}}\n",
            "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 110}}\n",
            "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 110}}\n",
            "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 100}}\n",
            "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 100}}\n",
            "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 90}}\n",
            "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 90}}\n",
            "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 70}}\n",
            "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 70}}\n",
            "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 60}}\n",
            "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 55}}\n",
            "\tLightGBMLarge_BAG_L1: \t{'num_boost_round': 10000, 'num_threads': -1, 'objective': 'multiclass', 'num_classes': 3, 'verbose': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'two_round': True, 'seed_value': 0, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
            "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 1799.69s of the 3599.33s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 16 features (12 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 277, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.9781264, Val log_loss: -0.8716570455369765\n",
            "Epoch 10.  Train loss: 0.77996594, Val log_loss: -0.8085583987929496\n",
            "Epoch 20.  Train loss: 0.7428382, Val log_loss: -0.8003739926489584\n",
            "Epoch 30.  Train loss: 0.7147766, Val log_loss: -0.7946150019262985\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 37)\n",
            "Best model found in epoch 34. Val log_loss: -0.7810445578370415\n",
            "\tFitting S1F2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 16 features (12 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 277, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.9328483, Val log_loss: -0.8683376948173895\n",
            "Epoch 10.  Train loss: 0.77512985, Val log_loss: -0.7981696608022295\n",
            "Epoch 20.  Train loss: 0.73991907, Val log_loss: -0.7878120024600549\n",
            "Epoch 30.  Train loss: 0.70664155, Val log_loss: -0.7855829071110637\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 38)\n",
            "Best model found in epoch 35. Val log_loss: -0.7816491502459293\n",
            "\tFitting S1F3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 16 features (12 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 277, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.9367481, Val log_loss: -0.8687417134811548\n",
            "Epoch 10.  Train loss: 0.7782105, Val log_loss: -0.7940386712068209\n",
            "Epoch 20.  Train loss: 0.7433181, Val log_loss: -0.7776737235844112\n",
            "Epoch 30.  Train loss: 0.70659953, Val log_loss: -0.7699854960855173\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 39)\n",
            "Best model found in epoch 39. Val log_loss: -0.7647557143561573\n",
            "\tFitting S1F4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 16 features (12 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 277, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.9449795, Val log_loss: -0.8621808435044231\n",
            "Epoch 10.  Train loss: 0.7802605, Val log_loss: -0.7931917237845768\n",
            "Epoch 20.  Train loss: 0.7469773, Val log_loss: -0.7765680568501105\n",
            "Epoch 30.  Train loss: 0.7105507, Val log_loss: -0.7743451625555021\n",
            "Epoch 40.  Train loss: 0.68216956, Val log_loss: -0.7766508723233242\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 41)\n",
            "Best model found in epoch 36. Val log_loss: -0.7672351394883461\n",
            "\tFitting S1F5 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 16 features (12 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 277, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.93737483, Val log_loss: -0.8666667239634899\n",
            "Epoch 10.  Train loss: 0.7800358, Val log_loss: -0.8022429321879184\n",
            "Epoch 20.  Train loss: 0.7409467, Val log_loss: -0.7978689464812961\n",
            "Epoch 30.  Train loss: 0.70856893, Val log_loss: -0.795344065821491\n",
            "Epoch 40.  Train loss: 0.68301994, Val log_loss: -0.7905454086444256\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 42)\n",
            "Best model found in epoch 36. Val log_loss: -0.78698441110381\n",
            "\tFitting S1F6 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 16 features (12 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 277, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.93583536, Val log_loss: -0.8669429562833845\n",
            "Epoch 10.  Train loss: 0.7697091, Val log_loss: -0.8084563908983059\n",
            "Epoch 20.  Train loss: 0.73404026, Val log_loss: -0.8069536226913502\n",
            "Epoch 30.  Train loss: 0.6962576, Val log_loss: -0.7981911981988695\n",
            "Epoch 40.  Train loss: 0.66912574, Val log_loss: -0.8018468858892657\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 44)\n",
            "Best model found in epoch 30. Val log_loss: -0.7981911981988695\n",
            "\tFitting S1F7 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 16 features (12 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 277, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.9676507, Val log_loss: -0.8615547015147955\n",
            "Epoch 10.  Train loss: 0.78177273, Val log_loss: -0.8080307160076866\n",
            "Epoch 20.  Train loss: 0.743363, Val log_loss: -0.8019661803769254\n",
            "Epoch 30.  Train loss: 0.7057678, Val log_loss: -0.7980756914832307\n",
            "Epoch 40.  Train loss: 0.6755697, Val log_loss: -0.7953302592278626\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 47)\n",
            "Best model found in epoch 44. Val log_loss: -0.7914445579604746\n",
            "\tFitting S1F8 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23812 examples, 16 features (12 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 277, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.93886155, Val log_loss: -0.8695930804557296\n",
            "Epoch 10.  Train loss: 0.7761474, Val log_loss: -0.8049796231091022\n",
            "Epoch 20.  Train loss: 0.7425571, Val log_loss: -0.7925784638197301\n",
            "Epoch 30.  Train loss: 0.7094059, Val log_loss: -0.7899440111675157\n",
            "Epoch 40.  Train loss: 0.6779966, Val log_loss: -0.7902699582416051\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 49)\n",
            "Best model found in epoch 38. Val log_loss: -0.7841089050030241\n",
            "\tFitting S1F9 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23812 examples, 16 features (12 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 277, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.9487911, Val log_loss: -0.8751099510882437\n",
            "Epoch 10.  Train loss: 0.7820395, Val log_loss: -0.8034568351388879\n",
            "Epoch 20.  Train loss: 0.7415565, Val log_loss: -0.7918153232217032\n",
            "Epoch 30.  Train loss: 0.71313775, Val log_loss: -0.7818870297911276\n",
            "Epoch 40.  Train loss: 0.6816918, Val log_loss: -0.7773680192102821\n",
            "Epoch 50.  Train loss: 0.65894383, Val log_loss: -0.7866031662877565\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 57)\n",
            "Best model found in epoch 47. Val log_loss: -0.7769368862387079\n",
            "\tFitting S1F10 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23812 examples, 16 features (12 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 277, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.96321404, Val log_loss: -0.8662900207060722\n",
            "Epoch 10.  Train loss: 0.7769159, Val log_loss: -0.8120853673039965\n",
            "Epoch 20.  Train loss: 0.7389194, Val log_loss: -0.7982649993235932\n",
            "Epoch 30.  Train loss: 0.7100893, Val log_loss: -0.7905007968433131\n",
            "Epoch 40.  Train loss: 0.6811628, Val log_loss: -0.7912913485600953\n",
            "Epoch 50.  Train loss: 0.6557148, Val log_loss: -0.7861881204278671\n",
            "Epoch 60.  Train loss: 0.6352348, Val log_loss: -0.7983699369656242\n",
            "\tRan out of time, stopping training early. (Stopping on epoch 68)\n",
            "Best model found in epoch 56. Val log_loss: -0.7810277647266626\n",
            "Saving AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L1/utils/oof.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L1/model.pkl\n",
            "\t-0.7813\t = Validation log_loss score\n",
            "\t1731.67s\t = Training runtime\n",
            "\t4.4s\t = Validation runtime\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 63.48s of the 1863.13s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': [0.1], 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 7/7 categorical features\n",
            "Using 9 cont features\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0): Embedding(4, 3)\n",
            "    (1): Embedding(4, 3)\n",
            "    (2): Embedding(4, 3)\n",
            "    (3): Embedding(7, 5)\n",
            "    (4): Embedding(7, 5)\n",
            "    (5): Embedding(7, 5)\n",
            "    (6): Embedding(8, 5)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=38, out_features=200, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.1, inplace=False)\n",
            "    (8): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with valid_loss value: 0.956810712814331.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 1 with valid_loss value: 0.8542788624763489.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tRan out of time, stopping training early.\n",
            "Better model found at epoch 2 with valid_loss value: 0.8256687521934509.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Model validation metrics: 0.8256687521934509\n",
            "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 56.58s of the 1856.23s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.03s \t= Train Time (Using 10000/23811 rows) (4.49s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23811/23811 rows) (4.44s remaining time)\n",
            "\tFitting S1F2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23811 rows) (4.98s remaining time)\n",
            "\t0.06s \t= Train Time (Using 23811/23811 rows) (4.92s remaining time)\n",
            "\tFitting S1F3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23811 rows) (5.58s remaining time)\n",
            "\t0.06s \t= Train Time (Using 23811/23811 rows) (5.53s remaining time)\n",
            "\tFitting S1F4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23811 rows) (6.36s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23811/23811 rows) (6.31s remaining time)\n",
            "\tFitting S1F5 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23811 rows) (7.4s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23811/23811 rows) (7.35s remaining time)\n",
            "\tFitting S1F6 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.03s \t= Train Time (Using 10000/23811 rows) (8.85s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23811/23811 rows) (8.8s remaining time)\n",
            "\tFitting S1F7 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.03s \t= Train Time (Using 10000/23811 rows) (11.03s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23811/23811 rows) (10.98s remaining time)\n",
            "\tFitting S1F8 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23812 rows) (14.66s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23812/23812 rows) (14.61s remaining time)\n",
            "\tFitting S1F9 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23812 rows) (21.93s remaining time)\n",
            "\t0.06s \t= Train Time (Using 23812/23812 rows) (21.87s remaining time)\n",
            "\tFitting S1F10 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23812 rows) (43.7s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23812/23812 rows) (43.65s remaining time)\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L1/model.pkl\n",
            "\t-2.0219\t = Validation log_loss score\n",
            "\t0.95s\t = Training runtime\n",
            "\t1.08s\t = Validation runtime\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 54.42s of the 1854.07s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.03s \t= Train Time (Using 10000/23811 rows) (4.32s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23811/23811 rows) (4.27s remaining time)\n",
            "\tFitting S1F2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23811 rows) (4.79s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23811/23811 rows) (4.74s remaining time)\n",
            "\tFitting S1F3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23811 rows) (5.37s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23811/23811 rows) (5.32s remaining time)\n",
            "\tFitting S1F4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.03s \t= Train Time (Using 10000/23811 rows) (6.11s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23811/23811 rows) (6.06s remaining time)\n",
            "\tFitting S1F5 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.03s \t= Train Time (Using 10000/23811 rows) (7.11s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23811/23811 rows) (7.05s remaining time)\n",
            "\tFitting S1F6 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23811 rows) (8.5s remaining time)\n",
            "\t0.06s \t= Train Time (Using 23811/23811 rows) (8.45s remaining time)\n",
            "\tFitting S1F7 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23811 rows) (10.59s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23811/23811 rows) (10.54s remaining time)\n",
            "\tFitting S1F8 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.03s \t= Train Time (Using 10000/23812 rows) (14.08s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23812/23812 rows) (14.02s remaining time)\n",
            "\tFitting S1F9 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23812 rows) (21.05s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23812/23812 rows) (20.99s remaining time)\n",
            "\tFitting S1F10 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.02s \t= Train Time (Using 10000/23812 rows) (41.95s remaining time)\n",
            "\t0.05s \t= Train Time (Using 23812/23812 rows) (41.9s remaining time)\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L1/model.pkl\n",
            "\t-2.5637\t = Validation log_loss score\n",
            "\t0.95s\t = Training runtime\n",
            "\t1.09s\t = Validation runtime\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 52.23s of the 1851.88s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 80 due to low time. Expected time usage reduced from 15.5s -> 4.2s...\n",
            "\tFitting S1F2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 84 due to low time. Expected time usage reduced from 15.5s -> 4.4s...\n",
            "\tFitting S1F3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 87 due to low time. Expected time usage reduced from 15.5s -> 4.6s...\n",
            "\tFitting S1F4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 93 due to low time. Expected time usage reduced from 15.5s -> 4.8s...\n",
            "\tFitting S1F5 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 65 due to low time. Expected time usage reduced from 23.5s -> 5.2s...\n",
            "\tFitting S1F6 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 111 due to low time. Expected time usage reduced from 15.5s -> 5.7s...\n",
            "\tFitting S1F7 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 121 due to low time. Expected time usage reduced from 15.5s -> 6.3s...\n",
            "\tFitting S1F8 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 136 due to low time. Expected time usage reduced from 15.8s -> 7.2s...\n",
            "\tFitting S1F9 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 166 due to low time. Expected time usage reduced from 15.8s -> 8.8s...\n",
            "\tFitting S1F10 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 232 due to low time. Expected time usage reduced from 15.5s -> 12.0s...\n",
            "Saving AutogluonModels/ag-20210406_125856/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/RandomForestGini_BAG_L1/model.pkl\n",
            "\t-0.8134\t = Validation log_loss score\n",
            "\t43.62s\t = Training runtime\n",
            "\t1.41s\t = Validation runtime\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2.46s of the 1802.1s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Model is expected to require 15.6s to train, which exceeds the maximum time limit of 0.2s, skipping model...\n",
            "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L1.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2.17s of the 1801.81s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Model is expected to require 7.9s to train, which exceeds the maximum time limit of 0.2s, skipping model...\n",
            "\tTime limit exceeded... Skipping ExtraTreesGini_BAG_L1.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2.0s of the 1801.64s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Model is expected to require 15.5s to train, which exceeds the maximum time limit of 0.2s, skipping model...\n",
            "\tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L1.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1.71s of the 1801.35s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Training Gradient Boosting Model for 10000 rounds...\n",
            "with the following hyperparameter settings:\n",
            "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'multiclass', 'num_classes': 3, 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True}\n",
            "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\t[1]\ttrain_set's multi_logloss: 0.872654\tvalid_set's multi_logloss: 0.873418\n",
            "\tTime limit exceeded... Skipping LightGBM_BAG_L1.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1.34s of the 1800.98s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Training Gradient Boosting Model for 10000 rounds...\n",
            "with the following hyperparameter settings:\n",
            "{'num_threads': -1, 'learning_rate': 0.05, 'objective': 'multiclass', 'num_classes': 3, 'verbose': -1, 'boosting_type': 'gbdt', 'two_round': True, 'extra_trees': True}\n",
            "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
            "\t[1]\ttrain_set's multi_logloss: 0.879903\tvalid_set's multi_logloss: 0.880582\n",
            "\tTime limit exceeded... Skipping LightGBMXT_BAG_L1.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1.03s of the 1800.67s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'MultiClass'}\n",
            "\tTime limit exceeded... Skipping CatBoost_BAG_L1.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 0.49s of the 1800.13s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Ran out of time, early stopping on iteration 0. Best iteration is: \t[0]\t1.054811\n",
            "\tTime limit exceeded... Skipping XGBoost_BAG_L1.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Not enough time left to finish repeated k-fold bagging, stopping early ...\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L1/utils/oof.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1799.47s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Ensemble size: 67\n",
            "Ensemble weights: \n",
            "[0.402985 0.41791  0.104478 0.074627]\n",
            "Saving AutogluonModels/ag-20210406_125856/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/WeightedEnsemble_L2/model.pkl\n",
            "\t-0.7173\t = Validation log_loss score\n",
            "\t5.71s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tNeuralNetMXNet_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.tabular_nn_model.TabularNeuralNetModel'>, 'priority': 120}}\n",
            "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 115}}\n",
            "\tKNeighborsUnif_BAG_L2: \t{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 110}}\n",
            "\tKNeighborsDist_BAG_L2: \t{'weights': 'distance', 'ag_args': {'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 110}}\n",
            "\tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 100}}\n",
            "\tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 100}}\n",
            "\tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 90}}\n",
            "\tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 90}}\n",
            "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 70}}\n",
            "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 70}}\n",
            "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 60}}\n",
            "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 55}}\n",
            "\tLightGBMLarge_BAG_L2: \t{'num_boost_round': 10000, 'num_threads': -1, 'objective': 'multiclass', 'num_classes': 3, 'verbose': -1, 'boosting_type': 'gbdt', 'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'two_round': True, 'seed_value': 0, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L1/utils/oof.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
            "Fitting model: NeuralNetMXNet_BAG_L2 ... Training model for up to 1793.71s of the 1793.67s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L2/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"KNeighborsUnif_BAG_L1_2\",\n",
            "        \"KNeighborsDist_BAG_L1_2\",\n",
            "        \"RandomForestGini_BAG_L1_2\",\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"NeuralNetMXNet_BAG_L1_0\",\n",
            "        \"NeuralNetMXNet_BAG_L1_1\",\n",
            "        \"NeuralNetMXNet_BAG_L1_2\",\n",
            "        \"KNeighborsUnif_BAG_L1_0\",\n",
            "        \"KNeighborsUnif_BAG_L1_1\",\n",
            "        \"KNeighborsDist_BAG_L1_0\",\n",
            "        \"KNeighborsDist_BAG_L1_1\",\n",
            "        \"RandomForestGini_BAG_L1_0\",\n",
            "        \"RandomForestGini_BAG_L1_1\",\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 28 features (24 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 351, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.7694372, Val log_loss: -0.7203803406444041\n",
            "Epoch 10.  Train loss: 0.65742975, Val log_loss: -0.7110169242274859\n",
            "Epoch 20.  Train loss: 0.62140447, Val log_loss: -0.7176040765274674\n",
            "Best model found in epoch 3. Val log_loss: -0.7035388363425311\n",
            "\tFitting S1F2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"KNeighborsUnif_BAG_L1_2\",\n",
            "        \"KNeighborsDist_BAG_L1_2\",\n",
            "        \"RandomForestGini_BAG_L1_2\",\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"NeuralNetMXNet_BAG_L1_0\",\n",
            "        \"NeuralNetMXNet_BAG_L1_1\",\n",
            "        \"NeuralNetMXNet_BAG_L1_2\",\n",
            "        \"KNeighborsUnif_BAG_L1_0\",\n",
            "        \"KNeighborsUnif_BAG_L1_1\",\n",
            "        \"KNeighborsDist_BAG_L1_0\",\n",
            "        \"KNeighborsDist_BAG_L1_1\",\n",
            "        \"RandomForestGini_BAG_L1_0\",\n",
            "        \"RandomForestGini_BAG_L1_1\",\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 28 features (24 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 351, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.8009696, Val log_loss: -0.726892879477738\n",
            "Epoch 10.  Train loss: 0.65845954, Val log_loss: -0.7126688752492336\n",
            "Epoch 20.  Train loss: 0.6199275, Val log_loss: -0.7315987105800215\n",
            "Best model found in epoch 6. Val log_loss: -0.7105820814284157\n",
            "\tFitting S1F3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"KNeighborsUnif_BAG_L1_2\",\n",
            "        \"KNeighborsDist_BAG_L1_2\",\n",
            "        \"RandomForestGini_BAG_L1_2\",\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"NeuralNetMXNet_BAG_L1_0\",\n",
            "        \"NeuralNetMXNet_BAG_L1_1\",\n",
            "        \"NeuralNetMXNet_BAG_L1_2\",\n",
            "        \"KNeighborsUnif_BAG_L1_0\",\n",
            "        \"KNeighborsUnif_BAG_L1_1\",\n",
            "        \"KNeighborsDist_BAG_L1_0\",\n",
            "        \"KNeighborsDist_BAG_L1_1\",\n",
            "        \"RandomForestGini_BAG_L1_0\",\n",
            "        \"RandomForestGini_BAG_L1_1\",\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 28 features (24 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 351, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.8001145, Val log_loss: -0.71526253113181\n",
            "Epoch 10.  Train loss: 0.66098744, Val log_loss: -0.7009746698185362\n",
            "Epoch 20.  Train loss: 0.6201117, Val log_loss: -0.7166525634732139\n",
            "Best model found in epoch 6. Val log_loss: -0.6995150186318569\n",
            "\tFitting S1F4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"KNeighborsUnif_BAG_L1_2\",\n",
            "        \"KNeighborsDist_BAG_L1_2\",\n",
            "        \"RandomForestGini_BAG_L1_2\",\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"NeuralNetMXNet_BAG_L1_0\",\n",
            "        \"NeuralNetMXNet_BAG_L1_1\",\n",
            "        \"NeuralNetMXNet_BAG_L1_2\",\n",
            "        \"KNeighborsUnif_BAG_L1_0\",\n",
            "        \"KNeighborsUnif_BAG_L1_1\",\n",
            "        \"KNeighborsDist_BAG_L1_0\",\n",
            "        \"KNeighborsDist_BAG_L1_1\",\n",
            "        \"RandomForestGini_BAG_L1_0\",\n",
            "        \"RandomForestGini_BAG_L1_1\",\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 28 features (24 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 351, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.7954432, Val log_loss: -0.7070727816311951\n",
            "Epoch 10.  Train loss: 0.6609154, Val log_loss: -0.6949817708687109\n",
            "Epoch 20.  Train loss: 0.618552, Val log_loss: -0.7088305882304253\n",
            "Best model found in epoch 3. Val log_loss: -0.6935909134634993\n",
            "\tFitting S1F5 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"KNeighborsUnif_BAG_L1_2\",\n",
            "        \"KNeighborsDist_BAG_L1_2\",\n",
            "        \"RandomForestGini_BAG_L1_2\",\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"NeuralNetMXNet_BAG_L1_0\",\n",
            "        \"NeuralNetMXNet_BAG_L1_1\",\n",
            "        \"NeuralNetMXNet_BAG_L1_2\",\n",
            "        \"KNeighborsUnif_BAG_L1_0\",\n",
            "        \"KNeighborsUnif_BAG_L1_1\",\n",
            "        \"KNeighborsDist_BAG_L1_0\",\n",
            "        \"KNeighborsDist_BAG_L1_1\",\n",
            "        \"RandomForestGini_BAG_L1_0\",\n",
            "        \"RandomForestGini_BAG_L1_1\",\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 28 features (24 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 351, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.7946051, Val log_loss: -0.7164890537205985\n",
            "Epoch 10.  Train loss: 0.6575762, Val log_loss: -0.7009100024352584\n",
            "Epoch 20.  Train loss: 0.6198865, Val log_loss: -0.7125964726659998\n",
            "Best model found in epoch 7. Val log_loss: -0.6966974095948947\n",
            "\tFitting S1F6 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"KNeighborsUnif_BAG_L1_2\",\n",
            "        \"KNeighborsDist_BAG_L1_2\",\n",
            "        \"RandomForestGini_BAG_L1_2\",\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"NeuralNetMXNet_BAG_L1_0\",\n",
            "        \"NeuralNetMXNet_BAG_L1_1\",\n",
            "        \"NeuralNetMXNet_BAG_L1_2\",\n",
            "        \"KNeighborsUnif_BAG_L1_0\",\n",
            "        \"KNeighborsUnif_BAG_L1_1\",\n",
            "        \"KNeighborsDist_BAG_L1_0\",\n",
            "        \"KNeighborsDist_BAG_L1_1\",\n",
            "        \"RandomForestGini_BAG_L1_0\",\n",
            "        \"RandomForestGini_BAG_L1_1\",\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 28 features (24 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 351, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.784767, Val log_loss: -0.713680819248554\n",
            "Epoch 10.  Train loss: 0.65889585, Val log_loss: -0.7022516458166463\n",
            "Epoch 20.  Train loss: 0.6244937, Val log_loss: -0.7135285171092356\n",
            "Epoch 30.  Train loss: 0.5786355, Val log_loss: -0.7339203856520788\n",
            "Best model found in epoch 10. Val log_loss: -0.7022516458166463\n",
            "\tFitting S1F7 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"KNeighborsUnif_BAG_L1_2\",\n",
            "        \"KNeighborsDist_BAG_L1_2\",\n",
            "        \"RandomForestGini_BAG_L1_2\",\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"NeuralNetMXNet_BAG_L1_0\",\n",
            "        \"NeuralNetMXNet_BAG_L1_1\",\n",
            "        \"NeuralNetMXNet_BAG_L1_2\",\n",
            "        \"KNeighborsUnif_BAG_L1_0\",\n",
            "        \"KNeighborsUnif_BAG_L1_1\",\n",
            "        \"KNeighborsDist_BAG_L1_0\",\n",
            "        \"KNeighborsDist_BAG_L1_1\",\n",
            "        \"RandomForestGini_BAG_L1_0\",\n",
            "        \"RandomForestGini_BAG_L1_1\",\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23811 examples, 28 features (24 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 351, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.8022692, Val log_loss: -0.7164627442788263\n",
            "Epoch 10.  Train loss: 0.65853494, Val log_loss: -0.7136156242200014\n",
            "Epoch 20.  Train loss: 0.62582904, Val log_loss: -0.7228230035135935\n",
            "Best model found in epoch 2. Val log_loss: -0.7091281821476809\n",
            "\tFitting S1F8 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"KNeighborsUnif_BAG_L1_2\",\n",
            "        \"KNeighborsDist_BAG_L1_2\",\n",
            "        \"RandomForestGini_BAG_L1_2\",\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"NeuralNetMXNet_BAG_L1_0\",\n",
            "        \"NeuralNetMXNet_BAG_L1_1\",\n",
            "        \"NeuralNetMXNet_BAG_L1_2\",\n",
            "        \"KNeighborsUnif_BAG_L1_0\",\n",
            "        \"KNeighborsUnif_BAG_L1_1\",\n",
            "        \"KNeighborsDist_BAG_L1_0\",\n",
            "        \"KNeighborsDist_BAG_L1_1\",\n",
            "        \"RandomForestGini_BAG_L1_0\",\n",
            "        \"RandomForestGini_BAG_L1_1\",\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23812 examples, 28 features (24 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 351, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.78531873, Val log_loss: -0.7120320869627319\n",
            "Epoch 10.  Train loss: 0.6571909, Val log_loss: -0.6986366266419931\n",
            "Epoch 20.  Train loss: 0.6214948, Val log_loss: -0.7080478909451845\n",
            "Best model found in epoch 6. Val log_loss: -0.6957411460754495\n",
            "\tFitting S1F9 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"KNeighborsUnif_BAG_L1_2\",\n",
            "        \"KNeighborsDist_BAG_L1_2\",\n",
            "        \"RandomForestGini_BAG_L1_2\",\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"NeuralNetMXNet_BAG_L1_0\",\n",
            "        \"NeuralNetMXNet_BAG_L1_1\",\n",
            "        \"NeuralNetMXNet_BAG_L1_2\",\n",
            "        \"KNeighborsUnif_BAG_L1_0\",\n",
            "        \"KNeighborsUnif_BAG_L1_1\",\n",
            "        \"KNeighborsDist_BAG_L1_0\",\n",
            "        \"KNeighborsDist_BAG_L1_1\",\n",
            "        \"RandomForestGini_BAG_L1_0\",\n",
            "        \"RandomForestGini_BAG_L1_1\",\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23812 examples, 28 features (24 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 351, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.7722232, Val log_loss: -0.7218510444467933\n",
            "Epoch 10.  Train loss: 0.6615536, Val log_loss: -0.7097348842093816\n",
            "Epoch 20.  Train loss: 0.62086874, Val log_loss: -0.7239940206182237\n",
            "Best model found in epoch 5. Val log_loss: -0.7064604809377448\n",
            "\tFitting S1F10 with 'num_gpus': 0, 'num_cpus': 2\n",
            "AutoGluon Neural Network infers features are of the following types:\n",
            "{\n",
            "    \"continuous\": [\n",
            "        \"KNeighborsUnif_BAG_L1_2\",\n",
            "        \"KNeighborsDist_BAG_L1_2\",\n",
            "        \"RandomForestGini_BAG_L1_2\",\n",
            "        \"DAYS_BIRTH\",\n",
            "        \"begin_month\"\n",
            "    ],\n",
            "    \"skewed\": [\n",
            "        \"NeuralNetMXNet_BAG_L1_0\",\n",
            "        \"NeuralNetMXNet_BAG_L1_1\",\n",
            "        \"NeuralNetMXNet_BAG_L1_2\",\n",
            "        \"KNeighborsUnif_BAG_L1_0\",\n",
            "        \"KNeighborsUnif_BAG_L1_1\",\n",
            "        \"KNeighborsDist_BAG_L1_0\",\n",
            "        \"KNeighborsDist_BAG_L1_1\",\n",
            "        \"RandomForestGini_BAG_L1_0\",\n",
            "        \"RandomForestGini_BAG_L1_1\",\n",
            "        \"child_num\",\n",
            "        \"income_total\",\n",
            "        \"DAYS_EMPLOYED\",\n",
            "        \"family_size\"\n",
            "    ],\n",
            "    \"onehot\": [\n",
            "        \"work_phone\",\n",
            "        \"phone\",\n",
            "        \"email\",\n",
            "        \"gender\",\n",
            "        \"car\",\n",
            "        \"reality\"\n",
            "    ],\n",
            "    \"embed\": [\n",
            "        \"income_type\",\n",
            "        \"edu_type\",\n",
            "        \"family_type\",\n",
            "        \"house_type\"\n",
            "    ],\n",
            "    \"language\": []\n",
            "}\n",
            "\n",
            "\n",
            "Training data for neural network has: 23812 examples, 28 features (24 vector, 4 embedding, 0 language)\n",
            "Training neural network for up to 500 epochs...\n",
            "Neural network architecture:\n",
            "EmbedNet(\n",
            "  (numeric_block): NumericBlock(\n",
            "    (body): Dense(None -> 351, Activation(relu))\n",
            "  )\n",
            "  (embed_blocks): HybridSequential(\n",
            "    (0): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (1): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (2): EmbedBlock(\n",
            "      (body): Embedding(6 -> 4, float32)\n",
            "    )\n",
            "    (3): EmbedBlock(\n",
            "      (body): Embedding(7 -> 4, float32)\n",
            "    )\n",
            "  )\n",
            "  (output_block): WideAndDeepBlock(\n",
            "    (deep): FeedforwardBlock(\n",
            "      (body): HybridSequential(\n",
            "        (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (1): Dropout(p = 0.1, axes=())\n",
            "        (2): Dense(None -> 256, Activation(relu))\n",
            "        (3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (4): Dropout(p = 0.1, axes=())\n",
            "        (5): Dense(None -> 128, Activation(relu))\n",
            "        (6): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None)\n",
            "        (7): Dropout(p = 0.1, axes=())\n",
            "        (8): Dense(None -> 3, linear)\n",
            "      )\n",
            "    )\n",
            "    (wide): Dense(None -> 3, linear)\n",
            "  )\n",
            ")\n",
            "Epoch 0.  Train loss: 0.805458, Val log_loss: -0.6971824026217646\n",
            "Epoch 10.  Train loss: 0.6551845, Val log_loss: -0.6879659257491166\n",
            "Epoch 20.  Train loss: 0.61373734, Val log_loss: -0.7011861742977652\n",
            "Best model found in epoch 5. Val log_loss: -0.6785852533016911\n",
            "Saving AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L2/utils/oof.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L2/model.pkl\n",
            "\t-0.6996\t = Validation log_loss score\n",
            "\t1016.38s\t = Training runtime\n",
            "\t4.39s\t = Validation runtime\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 772.81s of the 772.77s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': [0.1], 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 7/7 categorical features\n",
            "Using 21 cont features\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0): Embedding(4, 3)\n",
            "    (1): Embedding(4, 3)\n",
            "    (2): Embedding(4, 3)\n",
            "    (3): Embedding(7, 5)\n",
            "    (4): Embedding(7, 5)\n",
            "    (5): Embedding(7, 5)\n",
            "    (6): Embedding(8, 5)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=200, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.1, inplace=False)\n",
            "    (8): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with valid_loss value: 0.7715650796890259.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 1 with valid_loss value: 0.7227957844734192.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with valid_loss value: 0.7115008234977722.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 8 with valid_loss value: 0.7082757353782654.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tRan out of time, stopping training early.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Model validation metrics: 0.7082757353782654\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tFitting S1F2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': [0.1], 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 7/7 categorical features\n",
            "Using 21 cont features\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0): Embedding(4, 3)\n",
            "    (1): Embedding(4, 3)\n",
            "    (2): Embedding(4, 3)\n",
            "    (3): Embedding(7, 5)\n",
            "    (4): Embedding(7, 5)\n",
            "    (5): Embedding(7, 5)\n",
            "    (6): Embedding(8, 5)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=200, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.1, inplace=False)\n",
            "    (8): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with valid_loss value: 0.8109182715415955.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 1 with valid_loss value: 0.7339528203010559.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with valid_loss value: 0.7152897119522095.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 3 with valid_loss value: 0.7102711796760559.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 7 with valid_loss value: 0.7082566618919373.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 10 with valid_loss value: 0.7061042189598083.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 11 with valid_loss value: 0.7050994634628296.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tRan out of time, stopping training early.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Model validation metrics: 0.7050994634628296\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tFitting S1F3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': [0.1], 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 7/7 categorical features\n",
            "Using 21 cont features\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0): Embedding(4, 3)\n",
            "    (1): Embedding(4, 3)\n",
            "    (2): Embedding(4, 3)\n",
            "    (3): Embedding(7, 5)\n",
            "    (4): Embedding(7, 5)\n",
            "    (5): Embedding(7, 5)\n",
            "    (6): Embedding(8, 5)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=200, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.1, inplace=False)\n",
            "    (8): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with valid_loss value: 0.809809684753418.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 1 with valid_loss value: 0.7241920828819275.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with valid_loss value: 0.7209889888763428.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 3 with valid_loss value: 0.7088289260864258.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 4 with valid_loss value: 0.7063316106796265.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 5 with valid_loss value: 0.7031217217445374.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 11 with valid_loss value: 0.7014128565788269.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tRan out of time, stopping training early.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Model validation metrics: 0.7014128565788269\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tFitting S1F4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': [0.1], 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 7/7 categorical features\n",
            "Using 21 cont features\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0): Embedding(4, 3)\n",
            "    (1): Embedding(4, 3)\n",
            "    (2): Embedding(4, 3)\n",
            "    (3): Embedding(7, 5)\n",
            "    (4): Embedding(7, 5)\n",
            "    (5): Embedding(7, 5)\n",
            "    (6): Embedding(8, 5)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=200, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.1, inplace=False)\n",
            "    (8): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with valid_loss value: 0.7769639492034912.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 1 with valid_loss value: 0.7059353590011597.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with valid_loss value: 0.694254457950592.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 7 with valid_loss value: 0.6887409090995789.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 9 with valid_loss value: 0.6851687431335449.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 11 with valid_loss value: 0.6830753087997437.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tRan out of time, stopping training early.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Model validation metrics: 0.6830753087997437\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tFitting S1F5 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': [0.1], 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 7/7 categorical features\n",
            "Using 21 cont features\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0): Embedding(4, 3)\n",
            "    (1): Embedding(4, 3)\n",
            "    (2): Embedding(4, 3)\n",
            "    (3): Embedding(7, 5)\n",
            "    (4): Embedding(7, 5)\n",
            "    (5): Embedding(7, 5)\n",
            "    (6): Embedding(8, 5)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=200, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.1, inplace=False)\n",
            "    (8): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with valid_loss value: 0.7804862260818481.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 1 with valid_loss value: 0.7177014946937561.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with valid_loss value: 0.7127770185470581.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 3 with valid_loss value: 0.7040724158287048.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 5 with valid_loss value: 0.7037376761436462.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 8 with valid_loss value: 0.7022207379341125.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 11 with valid_loss value: 0.69939786195755.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 12 with valid_loss value: 0.693375289440155.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tRan out of time, stopping training early.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Model validation metrics: 0.693375289440155\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tFitting S1F6 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': [0.1], 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 7/7 categorical features\n",
            "Using 21 cont features\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0): Embedding(4, 3)\n",
            "    (1): Embedding(4, 3)\n",
            "    (2): Embedding(4, 3)\n",
            "    (3): Embedding(7, 5)\n",
            "    (4): Embedding(7, 5)\n",
            "    (5): Embedding(7, 5)\n",
            "    (6): Embedding(8, 5)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=200, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.1, inplace=False)\n",
            "    (8): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with valid_loss value: 0.7770556211471558.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 1 with valid_loss value: 0.714428722858429.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with valid_loss value: 0.7037774324417114.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tRan out of time, stopping training early.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Model validation metrics: 0.7037774324417114\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tFitting S1F7 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': [0.1], 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 7/7 categorical features\n",
            "Using 21 cont features\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0): Embedding(4, 3)\n",
            "    (1): Embedding(4, 3)\n",
            "    (2): Embedding(4, 3)\n",
            "    (3): Embedding(7, 5)\n",
            "    (4): Embedding(7, 5)\n",
            "    (5): Embedding(7, 5)\n",
            "    (6): Embedding(8, 5)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=200, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.1, inplace=False)\n",
            "    (8): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with valid_loss value: 0.7963077425956726.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 1 with valid_loss value: 0.7275005578994751.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with valid_loss value: 0.7113975286483765.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 4 with valid_loss value: 0.7107812166213989.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 5 with valid_loss value: 0.7074814438819885.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tRan out of time, stopping training early.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Model validation metrics: 0.7074814438819885\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tFitting S1F8 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': [0.1], 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 7/7 categorical features\n",
            "Using 21 cont features\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0): Embedding(4, 3)\n",
            "    (1): Embedding(4, 3)\n",
            "    (2): Embedding(4, 3)\n",
            "    (3): Embedding(7, 5)\n",
            "    (4): Embedding(7, 5)\n",
            "    (5): Embedding(7, 5)\n",
            "    (6): Embedding(8, 5)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=200, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.1, inplace=False)\n",
            "    (8): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with valid_loss value: 0.783917248249054.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 1 with valid_loss value: 0.7248491644859314.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with valid_loss value: 0.7069437503814697.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 3 with valid_loss value: 0.7060738801956177.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 4 with valid_loss value: 0.704651951789856.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 8 with valid_loss value: 0.6994609236717224.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 9 with valid_loss value: 0.6965751051902771.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tRan out of time, stopping training early.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Model validation metrics: 0.6965751051902771\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tFitting S1F9 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': [0.1], 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 7/7 categorical features\n",
            "Using 21 cont features\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0): Embedding(4, 3)\n",
            "    (1): Embedding(4, 3)\n",
            "    (2): Embedding(4, 3)\n",
            "    (3): Embedding(7, 5)\n",
            "    (4): Embedding(7, 5)\n",
            "    (5): Embedding(7, 5)\n",
            "    (6): Embedding(8, 5)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=200, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.1, inplace=False)\n",
            "    (8): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with valid_loss value: 0.7786785364151001.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 1 with valid_loss value: 0.7393924593925476.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with valid_loss value: 0.7133252024650574.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 3 with valid_loss value: 0.7061888575553894.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 5 with valid_loss value: 0.7058073282241821.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 6 with valid_loss value: 0.7048738598823547.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 8 with valid_loss value: 0.7038798928260803.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 10 with valid_loss value: 0.7026821970939636.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 14 with valid_loss value: 0.6981992721557617.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tRan out of time, stopping training early.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Model validation metrics: 0.6981992721557617\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\tFitting S1F10 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': [0.1], 'bs': 256, 'lr': 0.01, 'epochs': 30, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
            "Using 7/7 categorical features\n",
            "Using 21 cont features\n",
            "TabularModel(\n",
            "  (embeds): ModuleList(\n",
            "    (0): Embedding(4, 3)\n",
            "    (1): Embedding(4, 3)\n",
            "    (2): Embedding(4, 3)\n",
            "    (3): Embedding(7, 5)\n",
            "    (4): Embedding(7, 5)\n",
            "    (5): Embedding(7, 5)\n",
            "    (6): Embedding(8, 5)\n",
            "  )\n",
            "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
            "  (bn_cont): BatchNorm1d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=200, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Dropout(p=0.1, inplace=False)\n",
            "    (8): Linear(in_features=100, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with valid_loss value: 0.757808268070221.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 1 with valid_loss value: 0.7015895843505859.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 2 with valid_loss value: 0.6957688331604004.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 3 with valid_loss value: 0.6867622137069702.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 4 with valid_loss value: 0.6854692101478577.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Better model found at epoch 7 with valid_loss value: 0.679592490196228.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Model validation metrics: 0.679592490196228\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "█\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving AutogluonModels/ag-20210406_125856/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
            "\t-0.6977\t = Validation log_loss score\n",
            "\t730.05s\t = Training runtime\n",
            "\t2.78s\t = Validation runtime\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: KNeighborsUnif_BAG_L2 ... Training model for up to 39.83s of the 39.78s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L2/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23811 rows) (3.13s remaining time)\n",
            "\t0.1s \t= Train Time (Using 23811/23811 rows) (3.04s remaining time)\n",
            "\tFitting S1F2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23811 rows) (3.47s remaining time)\n",
            "\t0.09s \t= Train Time (Using 23811/23811 rows) (3.37s remaining time)\n",
            "\tFitting S1F3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23811 rows) (3.88s remaining time)\n",
            "\t0.1s \t= Train Time (Using 23811/23811 rows) (3.78s remaining time)\n",
            "\tFitting S1F4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.03s \t= Train Time (Using 10000/23811 rows) (4.41s remaining time)\n",
            "\t0.1s \t= Train Time (Using 23811/23811 rows) (4.31s remaining time)\n",
            "\tFitting S1F5 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23811 rows) (5.11s remaining time)\n",
            "\t0.1s \t= Train Time (Using 23811/23811 rows) (5.01s remaining time)\n",
            "\tFitting S1F6 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23811 rows) (6.1s remaining time)\n",
            "\t0.09s \t= Train Time (Using 23811/23811 rows) (6.01s remaining time)\n",
            "\tFitting S1F7 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23811 rows) (7.58s remaining time)\n",
            "\t0.09s \t= Train Time (Using 23811/23811 rows) (7.49s remaining time)\n",
            "\tFitting S1F8 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23812 rows) (10.04s remaining time)\n",
            "\t0.1s \t= Train Time (Using 23812/23812 rows) (9.94s remaining time)\n",
            "\tFitting S1F9 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23812 rows) (14.98s remaining time)\n",
            "\t0.09s \t= Train Time (Using 23812/23812 rows) (14.88s remaining time)\n",
            "\tFitting S1F10 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23812 rows) (29.77s remaining time)\n",
            "\t0.1s \t= Train Time (Using 23812/23812 rows) (29.67s remaining time)\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L2/utils/oof.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L2/model.pkl\n",
            "\t-2.0043\t = Validation log_loss score\n",
            "\t1.56s\t = Training runtime\n",
            "\t1.09s\t = Validation runtime\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: KNeighborsDist_BAG_L2 ... Training model for up to 36.96s of the 36.91s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L2/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.06s \t= Train Time (Using 10000/23811 rows) (2.89s remaining time)\n",
            "\t0.09s \t= Train Time (Using 23811/23811 rows) (2.8s remaining time)\n",
            "\tFitting S1F2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.03s \t= Train Time (Using 10000/23811 rows) (3.21s remaining time)\n",
            "\t0.09s \t= Train Time (Using 23811/23811 rows) (3.12s remaining time)\n",
            "\tFitting S1F3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23811 rows) (3.59s remaining time)\n",
            "\t0.1s \t= Train Time (Using 23811/23811 rows) (3.49s remaining time)\n",
            "\tFitting S1F4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23811 rows) (4.07s remaining time)\n",
            "\t0.1s \t= Train Time (Using 23811/23811 rows) (3.98s remaining time)\n",
            "\tFitting S1F5 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23811 rows) (4.73s remaining time)\n",
            "\t0.09s \t= Train Time (Using 23811/23811 rows) (4.63s remaining time)\n",
            "\tFitting S1F6 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23811 rows) (5.63s remaining time)\n",
            "\t0.1s \t= Train Time (Using 23811/23811 rows) (5.53s remaining time)\n",
            "\tFitting S1F7 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23811 rows) (7.0s remaining time)\n",
            "\t0.1s \t= Train Time (Using 23811/23811 rows) (6.89s remaining time)\n",
            "\tFitting S1F8 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.04s \t= Train Time (Using 10000/23812 rows) (9.27s remaining time)\n",
            "\t0.09s \t= Train Time (Using 23812/23812 rows) (9.18s remaining time)\n",
            "\tFitting S1F9 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.06s \t= Train Time (Using 10000/23812 rows) (13.78s remaining time)\n",
            "\t0.11s \t= Train Time (Using 23812/23812 rows) (13.68s remaining time)\n",
            "\tFitting S1F10 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\t0.06s \t= Train Time (Using 10000/23812 rows) (27.38s remaining time)\n",
            "\t0.13s \t= Train Time (Using 23812/23812 rows) (27.25s remaining time)\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L2/utils/oof.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L2/model.pkl\n",
            "\t-2.103\t = Validation log_loss score\n",
            "\t1.68s\t = Training runtime\n",
            "\t1.12s\t = Validation runtime\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 33.88s of the 33.84s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Model is expected to require 23.0s to train, which exceeds the maximum time limit of 2.7s, skipping model...\n",
            "\tTime limit exceeded... Skipping RandomForestGini_BAG_L2.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 33.49s of the 33.45s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Model is expected to require 38.1s to train, which exceeds the maximum time limit of 2.7s, skipping model...\n",
            "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L2.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 32.91s of the 32.87s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 50 due to low time. Expected time usage reduced from 15.6s -> 2.6s...\n",
            "\tFitting S1F2 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 52 due to low time. Expected time usage reduced from 15.5s -> 2.7s...\n",
            "\tFitting S1F3 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 53 due to low time. Expected time usage reduced from 15.8s -> 2.9s...\n",
            "\tFitting S1F4 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 57 due to low time. Expected time usage reduced from 15.8s -> 3.0s...\n",
            "\tFitting S1F5 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 62 due to low time. Expected time usage reduced from 15.6s -> 3.2s...\n",
            "\tFitting S1F6 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 67 due to low time. Expected time usage reduced from 15.5s -> 3.5s...\n",
            "\tFitting S1F7 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 74 due to low time. Expected time usage reduced from 15.5s -> 3.9s...\n",
            "\tFitting S1F8 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 83 due to low time. Expected time usage reduced from 15.9s -> 4.5s...\n",
            "\tFitting S1F9 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 103 due to low time. Expected time usage reduced from 15.8s -> 5.5s...\n",
            "\tFitting S1F10 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 143 due to low time. Expected time usage reduced from 15.5s -> 7.5s...\n",
            "Saving AutogluonModels/ag-20210406_125856/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/ExtraTreesGini_BAG_L2/model.pkl\n",
            "\t-0.7657\t = Validation log_loss score\n",
            "\t26.05s\t = Training runtime\n",
            "\t1.4s\t = Validation runtime\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 0.32s of the 0.28s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "\tWarning: Model is expected to require 15.9s to train, which exceeds the maximum time limit of 0.0s, skipping model...\n",
            "\tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L2.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Skipping LightGBM_BAG_L2 due to lack of time remaining.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Skipping LightGBMXT_BAG_L2 due to lack of time remaining.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Skipping CatBoost_BAG_L2 due to lack of time remaining.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Not enough time left to finish repeated k-fold bagging, stopping early ...\n",
            "Completed 1/20 k-fold bagging repeats ...\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L2/utils/oof.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L2/utils/oof.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L2/utils/oof.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -0.17s of remaining time.\n",
            "Saving AutogluonModels/ag-20210406_125856/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "\tFitting S1F1 with 'num_gpus': 0, 'num_cpus': 2\n",
            "Ensemble size: 100\n",
            "Ensemble weights: \n",
            "[0.23 0.14 0.62 0.   0.01]\n",
            "Saving AutogluonModels/ag-20210406_125856/models/WeightedEnsemble_L3/utils/oof.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/WeightedEnsemble_L3/model.pkl\n",
            "\t-0.6679\t = Validation log_loss score\n",
            "\t7.0s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 3607.25s ...\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/models/trainer.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/learner.pkl\n",
            "Saving AutogluonModels/ag-20210406_125856/predictor.pkl\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210406_125856/\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B-6wQhKB1Mb",
        "outputId": "b5ead456-daa0-49cc-d201-38693743a5a6"
      },
      "source": [
        "results = predictor.fit_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading: AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L1/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L1/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L1/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/RandomForestGini_BAG_L1/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/WeightedEnsemble_L2/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L2/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L2/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L2/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/ExtraTreesGini_BAG_L2/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/WeightedEnsemble_L3/model.pkl\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                      model  score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0       WeightedEnsemble_L3  -0.667935      17.684224  3558.355201                0.006301           6.998402            3       True         11\n",
            "1    NeuralNetFastAI_BAG_L2  -0.697687      10.766250  2507.242151                2.781144         730.052980            2       True          7\n",
            "2     NeuralNetMXNet_BAG_L2  -0.699610      12.379471  2793.573759                4.394365        1016.384588            2       True          6\n",
            "3       WeightedEnsemble_L2  -0.717285       7.994631  1782.897092                0.009525           5.707920            2       True          5\n",
            "4     ExtraTreesGini_BAG_L2  -0.765660       9.385274  1803.242397                1.400168          26.053226            2       True         10\n",
            "5     NeuralNetMXNet_BAG_L1  -0.781338       4.404058  1731.667959                4.404058        1731.667959            1       True          1\n",
            "6   RandomForestGini_BAG_L1  -0.813405       1.405387    43.624976                1.405387          43.624976            1       True          4\n",
            "7     KNeighborsUnif_BAG_L2  -2.004293       9.080022  1778.747053                1.094917           1.557882            2       True          8\n",
            "8     KNeighborsUnif_BAG_L1  -2.021880       1.084357     0.945135                1.084357           0.945135            1       True          2\n",
            "9     KNeighborsDist_BAG_L2  -2.103039       9.102246  1778.866006                1.117140           1.676835            2       True          9\n",
            "10    KNeighborsDist_BAG_L1  -2.563695       1.091304     0.951102                1.091304           0.951102            1       True          3\n",
            "Number of models trained: 11\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_KNN', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_TabularNeuralNet', 'WeightedEnsembleModel', 'StackerEnsembleModel_NNFastAiTabular'}\n",
            "Bagging used: True  (with 10 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', []) : 7 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "Plot summary of models saved to file: AutogluonModels/ag-20210406_125856/SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9TukyaIB6Mi",
        "outputId": "c1e2c8ba-3a3b-4c9a-a14d-9d5aa277db94"
      },
      "source": [
        "prediction=predictor.predict(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading: AutogluonModels/ag-20210406_125856/models/WeightedEnsemble_L3/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L1/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsUnif_BAG_L1/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L1/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/RandomForestGini_BAG_L1/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/ExtraTreesGini_BAG_L2/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/KNeighborsDist_BAG_L2/model.pkl\n",
            "Loading: AutogluonModels/ag-20210406_125856/models/NeuralNetFastAI_BAG_L2/model.pkl\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading: AutogluonModels/ag-20210406_125856/models/NeuralNetMXNet_BAG_L2/model.pkl\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBRZRAJZCg_n"
      },
      "source": [
        "submission=pd.read_csv(\"sample_submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "9EdL4uX-Cqvk",
        "outputId": "e665c275-75cb-4eb8-deb6-a99a109da35c"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26457</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26458</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26459</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26460</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26461</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>36452</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>36453</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>36454</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>36455</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>36456</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  0  1  2\n",
              "0     26457  0  0  0\n",
              "1     26458  0  0  0\n",
              "2     26459  0  0  0\n",
              "3     26460  0  0  0\n",
              "4     26461  0  0  0\n",
              "...     ... .. .. ..\n",
              "9995  36452  0  0  0\n",
              "9996  36453  0  0  0\n",
              "9997  36454  0  0  0\n",
              "9998  36455  0  0  0\n",
              "9999  36456  0  0  0\n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXzkCsV3PEtb",
        "outputId": "2cdb9ccf-0132-4d36-f5d9-269252d81b25"
      },
      "source": [
        "prediction.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3AJhvHUCoEz"
      },
      "source": [
        "for i in range(len(submission)):\n",
        "    if prediction[i]==0:\n",
        "        submission['0'][i]=1\n",
        "        submission['1'][i]=0\n",
        "        submission['2'][i]=0\n",
        "    elif prediction[i]==1:\n",
        "\n",
        "        submission['0'][i]=0\n",
        "        submission['1'][i]=1\n",
        "        submission['2'][i]=0\n",
        "    elif prediction[i]==2:\n",
        " \n",
        "        submission['0'][i]=0\n",
        "        submission['1'][i]=0\n",
        "        submission['2'][i]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "qxIf8lijQUmm",
        "outputId": "252ecde8-f6f0-43c2-ec78-0e7edbff30cb"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26457</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26458</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26459</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26460</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26461</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>36452</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>36453</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>36454</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>36455</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>36456</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  0  1  2\n",
              "0     26457  0  0  1\n",
              "1     26458  0  0  1\n",
              "2     26459  0  0  1\n",
              "3     26460  0  0  1\n",
              "4     26461  0  0  1\n",
              "...     ... .. .. ..\n",
              "9995  36452  0  0  1\n",
              "9996  36453  0  0  1\n",
              "9997  36454  0  0  1\n",
              "9998  36455  0  0  1\n",
              "9999  36456  0  0  1\n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "fWSkf3obPqqB",
        "outputId": "1ee6b57d-1cfe-4ed2-d81d-abccd6741798"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26457</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26458</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26459</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26460</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26461</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>36452</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>36453</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>36454</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>36455</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>36456</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  0  1  2\n",
              "0     26457  0  0  1\n",
              "1     26458  0  0  1\n",
              "2     26459  0  0  1\n",
              "3     26460  0  0  1\n",
              "4     26461  0  0  1\n",
              "...     ... .. .. ..\n",
              "9995  36452  0  0  1\n",
              "9996  36453  0  0  1\n",
              "9997  36454  0  0  1\n",
              "9998  36455  0  0  1\n",
              "9999  36456  0  0  1\n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvKsgpDIC0WX"
      },
      "source": [
        "submission.to_csv(\"result.csv\",index=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxfaAvsJDBoN",
        "outputId": "27c64178-2c09-42dd-b782-035c4e7d7de5"
      },
      "source": [
        "!kaggle competitions submit -c sejong-ai-challenge-p3 -f result.csv -m \"Message\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.10)\n",
            "100% 1.32k/1.32k [00:01<00:00, 736B/s]\n",
            "Successfully submitted to Sejong AI Challenge 문제3"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}